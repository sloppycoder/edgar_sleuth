import json
import logging
import logging.config
import sys
from pathlib import Path
from typing import Iterator

import click
import yaml

from . import chunk_filing, get_embeddings
from .datastore import execute_query
from .edgar import SECFiling
from .llm.embedding import GEMINI_EMBEDDING_MODEL
from .trustee import create_search_phrase_embeddings, extract_trustee_comp

MAX_ERRORS = 5

logger = logging.getLogger(__name__)

logger_config_path = Path.cwd() / "logger_config.yaml"
if logger_config_path.exists():
    with open(logger_config_path, "r") as f:
        logging.config.dictConfig(yaml.safe_load(f))


def create_filing(
    cik: str = "", accession_number: str = "", idx_filename: str = ""
) -> SECFiling:
    if idx_filename:
        return SECFiling(idx_filename=idx_filename)
    else:
        return SECFiling(cik=cik, accession_number=accession_number)


def enumerate_filings(batch: str, batch_limit: int) -> Iterator[SECFiling]:
    if batch.startswith("@"):
        with open(batch[1:], "r") as f:
            lines = f.readlines()
            lines = [
                line.strip()
                for line in lines
                if line.strip() and not line.startswith("#")
            ]
    else:
        lines = [batch]

    n_processed = 0
    for line in lines:
        if batch_limit and n_processed >= batch_limit:
            print("Reached batch limit of {batch_limit}. Exiting.")
            break

        try:
            entry = json.loads(line)
            if entry.get("idx_filename"):
                n_processed += 1
                yield SECFiling(idx_filename=entry["idx_filename"])
            elif entry.get("cik") and entry.get("accession_number"):
                n_processed += 1
                yield SECFiling(
                    cik=entry["cik"],
                    accession_number=entry["accession_number"],
                )
            else:
                print(f"ERROR: Ignored invalid entry: {entry}")
        except json.JSONDecodeError:
            print(f"ERROR: invalid json {line}")


def log_n_print(message):
    print(message)
    logger.info(message)


@click.command()
@click.argument(
    "action",
    type=click.Choice(
        ["initdb", "init", "chunk", "embedding", "extract"], case_sensitive=False
    ),
)
@click.option(
    "--full",
    is_flag=True,
    help="""
Run the predesccor steps prior to the action, e.g.
embedding depends on data generated by chunk, if full is set,
chunk will be run before embedding""",
)
@click.option(
    "--batch",
    help="""JSON string filings to process:
@<jsonl_file> with list of filings or inline string like\n
'{"cik": "1035018", "accession_number": "0001193125-20-000327"}"
'{"idx_filename": "edgar/data/1002427/0001133228-24-004879.txt"}"
""",
)
@click.option(
    "--batch-limit",
    type=int,
    default=0,
    help="Number of records to process in batch mode, 0 means unlimited",
)
@click.option(
    "--tags",
    "tags_str",
    required=False,
    help="tag for text chunks and embedding, required when using chunk, embedding and extract",  # noqa: E501
)
@click.option(
    "--search-tag",
    required=False,
    help="tag for search phrases, required when using search phrase, i.e. init, extract",
)
@click.option(
    "--dimension",
    type=int,
    default=768,
    help="Dimensionality of embeddings. Only applicable when using Gemini API",
)
@click.option("--dryrun", is_flag=True, help="Print filing only, does not run any action")
# ruff: noqa: C901
def main(
    action: str,
    dryrun: bool,
    full: bool,
    batch: str,
    batch_limit: int,
    tags_str: str,
    search_tag: str,
    dimension: int,
) -> None:
    # validate tag values first.
    if not search_tag and action in ["init", "initdb", "extract"]:
        raise click.UsageError(
            "--search-tag is required when search phrase are used, e.g. init, extract"
        )
    else:
        search_tag = search_tag.split(",")[0] if search_tag else ""

    if action in ["embedding", "extract"] and (not tags_str or "," in tags_str):
        raise click.UsageError(
            "--tags must be a single tag, without comma, when action is embedding or extract"  # noqa: E501
        )

    if action in ["chunk"] and not tags_str:
        raise click.UsageError("--tags is required when action is chunk")

    tags = tags_str.split(",") if tags_str else []

    log_n_print(f"Running {action} with tags {tags} and search tag {search_tag}")

    # hard coded values for now
    text_table_name = "filing_text_chunks"
    embedding_table_name = "filing_chunks_embeddings"
    search_phrase_table_name = "search_phrase_embeddings"
    form_type = "485BPOS"

    answer = "no"
    if action == "initdb":
        answer = input("This will drop all tables, are you sure? (yes/no): ")
        if answer.lower() == "yes":
            for table_name in [
                text_table_name,
                embedding_table_name,
                search_phrase_table_name,
            ]:
                print(f"Dropping table {table_name}")
                execute_query(f"DROP TABLE IF EXISTS {table_name}")

    if action == "init" or (action == "initdb" and answer.lower() == "yes"):
        print("Initializing search phrase embeddings...")
        create_search_phrase_embeddings(
            search_phrase_table_name,
            model=GEMINI_EMBEDDING_MODEL,
            tag=search_tag,
            dimension=dimension,
        )
        return

    elif action not in ["chunk", "embedding", "extract"]:
        print(f"Unknown action {action}")
        return

    n_errors = 0

    for filing in enumerate_filings(batch, batch_limit):
        if dryrun:
            print(filing)
            continue

        if n_errors > MAX_ERRORS:
            log_n_print(f"Aborting after reaching max errors: {MAX_ERRORS}")
            break

        if action == "chunk" or (action in ["extract", "embedding"] and full):
            n_chunks = chunk_filing(
                filing=filing,
                form_type=form_type,
                tags=tags,
                table_name=text_table_name,
            )
            if n_chunks > 1:
                log_n_print(f"{filing} {form_type} splitted into {n_chunks} chunks")
            else:
                log_n_print(f"Error when splitting {filing} {form_type}")
                n_errors += 1

        if action == "embedding" or (action in ["extract"] and full):
            n_chunks = get_embeddings(
                text_table_name=text_table_name,
                cik=filing.cik,
                accession_number=filing.accession_number,
                tag=tags[0],
                embedding_table_name=embedding_table_name,
                dimension=dimension,
            )
            if n_chunks > 1:
                log_n_print(f"Saved {n_chunks} embeddings for {filing} {form_type}")
            else:
                log_n_print(f"Error when get embeddings for {filing} {form_type}")
                n_errors += 1

        if action == "extract":
            model = "gemini-1.5-flash-002"
            response, comp_info = extract_trustee_comp(
                cik=filing.cik,
                accession_number=filing.accession_number,
                text_table_name=text_table_name,
                embedding_table_name=embedding_table_name,
                search_phrase_table_name=search_phrase_table_name,
                tag=tags[0],
                search_phrase_tag=search_tag,
                model=model,
            )
            logger.debug(f"{model} response:{response}")
            n_trustees = len(comp_info["trustees"]) if comp_info else 0
            log_n_print(f"Extracted {n_trustees} from {filing}")


if __name__ == "__main__":
    main(sys.argv[1:])
